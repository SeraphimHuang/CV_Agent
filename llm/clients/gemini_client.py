"""
Google Gemini å®¢æˆ·ç«¯å®ç°
ä½¿ç”¨ OpenAI SDK é€šè¿‡ Gemini çš„ OpenAI å…¼å®¹æ¥å£
"""

from openai import AsyncOpenAI
from config.prompt_manager import PromptManager
from llm.base_client import BaseLLMClient


class GeminiClient(BaseLLMClient):
    """Google Gemini å®¢æˆ·ç«¯ï¼ˆé€šè¿‡ OpenAI å…¼å®¹æ¥å£ï¼‰"""
    
    def __init__(self, api_key: str, prompt_manager: PromptManager):
        super().__init__(prompt_manager, 'gemini')
        self.client = AsyncOpenAI(
            api_key=api_key,
            base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
        )
    
    async def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨ Gemini APIï¼ˆé€šè¿‡ OpenAI å…¼å®¹æ¥å£ï¼‰"""
        print(f"ğŸŸ¡ Gemini API è°ƒç”¨å¼€å§‹ (OpenAI å…¼å®¹æ¨¡å¼)...")
        
        response = await self.client.chat.completions.create(
            model=self.config['model'],
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=self.config['temperature'],
            max_tokens=self.config.get('max_tokens', 2000)
        )
        
        print(f"ğŸŸ¡ Gemini API è°ƒç”¨å®Œæˆ")
        return response.choices[0].message.content
