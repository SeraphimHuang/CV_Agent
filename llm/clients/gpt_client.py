"""
OpenAI GPTå®¢æˆ·ç«¯å®ç°
"""

from langchain_openai import ChatOpenAI
from config.prompt_manager import PromptManager
from llm.base_client import BaseLLMClient


class GPTClient(BaseLLMClient):
    """OpenAI GPTå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str, prompt_manager: PromptManager):
        super().__init__(prompt_manager, 'gpt')
        self.client = ChatOpenAI(
            openai_api_key=api_key,
            model=self.config['model'],
            temperature=self.config['temperature'],
            max_tokens=self.config['max_tokens']
        )
    
    async def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨GPT API"""
        print(f"ğŸŸ¢ GPT API è°ƒç”¨å¼€å§‹...")
        response = await self.client.ainvoke(prompt)
        print(f"ğŸŸ¢ GPT API è°ƒç”¨å®Œæˆ")
        return response.content 