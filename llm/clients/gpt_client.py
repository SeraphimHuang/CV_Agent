"""
OpenAI GPT å®¢æˆ·ç«¯å®ç°
ä½¿ç”¨ OpenAI SDK åŸç”Ÿæ¥å£
"""

from openai import AsyncOpenAI
from config.prompt_manager import PromptManager
from llm.base_client import BaseLLMClient


class GPTClient(BaseLLMClient):
    """OpenAI GPT å®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str, prompt_manager: PromptManager):
        super().__init__(prompt_manager, 'gpt')
        self.client = AsyncOpenAI(api_key=api_key)
    
    async def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨ OpenAI GPT API"""
        print(f"ğŸŸ¢ GPT API è°ƒç”¨å¼€å§‹...")
        
        # GPT-5.x ç³»åˆ—ä½¿ç”¨ max_completion_tokensï¼Œè€Œä¸æ˜¯ max_tokens
        response = await self.client.chat.completions.create(
            model=self.config['model'],
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=self.config['temperature'],
            max_completion_tokens=self.config.get('max_tokens', 5000)
        )
        
        print(f"ğŸŸ¢ GPT API è°ƒç”¨å®Œæˆ")
        return response.choices[0].message.content
