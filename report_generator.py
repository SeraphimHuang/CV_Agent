"""
MarkdownæŠ¥å‘Šç”Ÿæˆå™¨
å°†LLMåˆ†æç»“æœç”Ÿæˆæ ¼å¼åŒ–çš„MarkdownæŠ¥å‘Š
"""

from typing import Dict, List, Any
from datetime import datetime


class MarkdownReportGenerator:
    """Markdownæ ¼å¼æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.report_content = []
    
    def _add_line(self, line: str = ""):
        """æ·»åŠ ä¸€è¡Œå†…å®¹åˆ°æŠ¥å‘Š"""
        self.report_content.append(line)
    
    def _add_header(self, text: str, level: int = 1):
        """æ·»åŠ æ ‡é¢˜"""
        prefix = "#" * level
        self._add_line(f"{prefix} {text}")
        self._add_line()
    
    def _add_quote(self, text: str):
        """æ·»åŠ å¼•ç”¨å—"""
        self._add_line(f"> {text}")
        self._add_line()
    
    def _add_list_item(self, text: str, level: int = 0):
        """æ·»åŠ åˆ—è¡¨é¡¹"""
        indent = "  " * level
        self._add_line(f"{indent}- {text}")
    
    def _add_ordered_item(self, text: str, number: int):
        """æ·»åŠ æœ‰åºåˆ—è¡¨é¡¹"""
        self._add_line(f"{number}. {text}")
    
    def _format_llm_results(self, llm_results: Dict[str, Dict[str, Any]], result_type: str) -> str:
        """æ ¼å¼åŒ–LLMç»“æœä¸ºå¯è¯»æ–‡æœ¬"""
        formatted_results = []
        
        for llm_name, result in llm_results.items():
            if result_type == "screening":
                citizenship = "æœ‰èº«ä»½è¦æ±‚" if result.get("citizenship_required") else "æ— èº«ä»½è¦æ±‚"
                senior_level = "è¦æ±‚é«˜çº§åˆ«" if result.get("senior_level_required") else "ä¸è¦æ±‚é«˜çº§åˆ«"
                reason = result.get("reason", "æ— ")
                formatted_results.append(f"**{llm_name.upper()}**: {citizenship}, {senior_level} - {reason}")
            
            elif result_type == "ranking":
                match_percentage = result.get("match_percentage", 0)
                error = result.get("error")
                if error:
                    formatted_results.append(f"**{llm_name.upper()}**: âŒ è°ƒç”¨å¤±è´¥ - {error}")
                else:
                    formatted_results.append(f"**{llm_name.upper()}**: åŒ¹é…åº¦ {match_percentage}%")
        
        return formatted_results
    
    def _should_reject_position(self, screening_results: Dict[str, Dict[str, Any]]) -> tuple[bool, List[str]]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‹’ç»è¯¥èŒä½ï¼ˆ>=2ä¸ªLLMè®¤ä¸ºä¸åˆé€‚ï¼‰
        
        Returns:
            tuple: (æ˜¯å¦æ‹’ç», æ‹’ç»åŸå› åˆ—è¡¨)
        """
        rejection_count = 0
        rejection_reasons = []
        
        for llm_name, result in screening_results.items():
            citizenship_required = result.get("citizenship_required", False)
            senior_level_required = result.get("senior_level_required", False)
            
            if citizenship_required or senior_level_required:
                rejection_count += 1
                reasons = []
                if citizenship_required:
                    reasons.append("æœ‰èº«ä»½è¦æ±‚")
                if senior_level_required:
                    reasons.append("è¦æ±‚é«˜çº§åˆ«ç»éªŒ")
                rejection_reasons.append(f"{llm_name}: {', '.join(reasons)}")
        
        should_reject = rejection_count >= 2
        return should_reject, rejection_reasons
    
    def _aggregate_experience_rankings(self, ranking_results: Dict[str, Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        èšåˆä¸‰ä¸ªLLMçš„ç»å†æ’åç»“æœ
        
        Returns:
            List[Dict]: æŒ‰æ€»åˆ†æ’åºçš„ç»å†åˆ—è¡¨
        """
        experience_scores = {}
        
        # æ”¶é›†æ‰€æœ‰LLMçš„æ’å
        for llm_name, result in ranking_results.items():
            if "error" in result:
                continue  # è·³è¿‡å¤±è´¥çš„LLM
                
            ranked_experiences = result.get("ranked_experiences", [])
            for exp in ranked_experiences:
                exp_id = exp.get("id")
                rank = exp.get("rank", 999)
                justification = exp.get("justification", "")
                
                if exp_id not in experience_scores:
                    experience_scores[exp_id] = {
                        "id": exp_id,
                        "total_score": 0,
                        "llm_rankings": {},
                        "count": 0
                    }
                
                experience_scores[exp_id]["total_score"] += rank
                experience_scores[exp_id]["llm_rankings"][llm_name] = {
                    "rank": rank,
                    "justification": justification
                }
                experience_scores[exp_id]["count"] += 1
        
        # è¡¥é½ç¼ºå¤±LLMè¯„åˆ†ï¼šæœªå‡ºç°çš„æŒ‰5åˆ†è®¡
        num_llms = len(ranking_results)
        for exp_data in experience_scores.values():
            missing = num_llms - exp_data["count"]
            if missing > 0:
                exp_data["total_score"] += missing * 5

        # æŒ‰æ€»åˆ†æ’åºï¼ˆåˆ†æ•°è¶Šä½è¶Šå¥½ï¼‰
        sorted_experiences = sorted(
            experience_scores.values(),
            key=lambda x: x["total_score"]
        )
        
        # è¿”å›æ‰€æœ‰å‡ºç°è¿‡çš„ç»å†ï¼Œå·²æŒ‰æ€»åˆ†æ’åº
        return sorted_experiences[:6]
    
    def generate_report(self, analysis_results: List[Dict[str, Any]], experiences_data: List[Dict[str, Any]]) -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„MarkdownæŠ¥å‘Š
        
        Args:
            analysis_results: æ‰€æœ‰èŒä½çš„åˆ†æç»“æœ
            experiences_data: ç»å†æ•°æ®ï¼ˆç”¨äºæ˜¾ç¤ºç»å†æ ‡é¢˜ï¼‰
            
        Returns:
            str: Markdownæ ¼å¼çš„æŠ¥å‘Šå†…å®¹
        """
        self.report_content = []  # é‡ç½®æŠ¥å‘Šå†…å®¹
        
        # æŠ¥å‘Šæ ‡é¢˜å’Œç”Ÿæˆä¿¡æ¯
        self._add_header("ç®€å†ä¼˜åŒ–åˆ†ææŠ¥å‘Š", 1)
        self._add_line(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        self._add_line(f"**åˆ†æèŒä½æ•°é‡**: {len(analysis_results)}")
        self._add_line(f"**ä½¿ç”¨LLM**: Gemini 2.5, GPT-5-mini Claude-4-Sonnet")
        self._add_line()
        
        # æˆ‘ä»¬ä»…ä½¿ç”¨ç»å†IDï¼Œä¸å†ä¾èµ– title å­—æ®µ
        
        # ç»Ÿè®¡ä¿¡æ¯
        suitable_count = 0
        rejected_count = 0
        
        for i, position_result in enumerate(analysis_results, 1):
            position_info = position_result["position_info"]
            screening_results = position_result["screening_results"]
            ranking_results = position_result.get("ranking_results", {})
            
            # èŒä½æ ‡é¢˜
            self._add_header(f"èŒä½ {i}: {position_info['company']} - {position_info['position']}", 2)
            
            # åŸºæœ¬ä¿¡æ¯
            self._add_line("**åŸºæœ¬ä¿¡æ¯**:")
            self._add_list_item(f"**å…¬å¸**: {position_info['company']}")
            self._add_list_item(f"**èŒä½**: {position_info['position']}")
            self._add_list_item(f"**åœ°ç‚¹**: {position_info['location']}")
            self._add_list_item(f"**é“¾æ¥**: {position_info['link']}")
            self._add_line()
            
            # ç­›é€‰ç»“æœ
            should_reject, rejection_reasons = self._should_reject_position(screening_results)
            
            if should_reject:
                rejected_count += 1
                self._add_header("ğŸš« ç­›é€‰ç»“æœï¼šä¸æ¨èæŠ•é€’", 3)
                self._add_quote("âŒ **è¯¥èŒä½ä¸ç¬¦åˆæŠ•é€’æ¡ä»¶ï¼Œå»ºè®®è·³è¿‡**")
                
                self._add_line("**æ‹’ç»åŸå› **:")
                for reason in rejection_reasons:
                    self._add_list_item(reason)
                self._add_line()
                
                self._add_line("**å„LLMè¯¦ç»†åˆ†æ**:")
                llm_formatted = self._format_llm_results(screening_results, "screening")
                for result_line in llm_formatted:
                    self._add_list_item(result_line)
                self._add_line()
                
            else:
                suitable_count += 1
                self._add_header("âœ… ç­›é€‰ç»“æœï¼šæ¨èæŠ•é€’", 3)
                self._add_quote("âœ… **è¯¥èŒä½ç¬¦åˆæŠ•é€’æ¡ä»¶ï¼Œå»ºè®®å‡†å¤‡ç”³è¯·ææ–™**")
                
                # ç­›é€‰è¯¦æƒ…
                self._add_line("**å„LLMç­›é€‰ç»“æœ**:")
                llm_formatted = self._format_llm_results(screening_results, "screening")
                for result_line in llm_formatted:
                    self._add_list_item(result_line)
                self._add_line()
                
                # å¦‚æœæœ‰æ’åç»“æœï¼Œæ˜¾ç¤ºæ¨èç»å†
                if ranking_results:
                    self._add_header("ğŸ“ æ¨èç»å† Top ", 3)
                    
                    # èšåˆæ’åç»“æœ
                    top_experiences = self._aggregate_experience_rankings(ranking_results)
                    
                    if top_experiences:
                        for rank, exp_data in enumerate(top_experiences, 1):
                            exp_id = exp_data["id"]
                            total_score = exp_data["total_score"]
                            
                            self._add_ordered_item(f"**{exp_id}** (æ€»åˆ†: {total_score})", rank)
                            
                            # æ˜¾ç¤ºå„LLMçš„è¯„ä»·
                            for llm_name, ranking_info in exp_data["llm_rankings"].items():
                                llm_rank = ranking_info["rank"]
                                justification = ranking_info["justification"]
                                self._add_list_item(f"**{llm_name}** (æ’å{llm_rank}): {justification}", 1)
                            
                            self._add_line()
                    else:
                        self._add_quote("âš ï¸ æ— æ³•è·å–æœ‰æ•ˆçš„ç»å†æ’åç»“æœ")
                
                # LLMåŒ¹é…åº¦ä¿¡æ¯
                self._add_line("**å„LLMåŒ¹é…åº¦è¯„ä¼°**:")
                ranking_formatted = self._format_llm_results(ranking_results, "ranking")
                for result_line in ranking_formatted:
                    self._add_list_item(result_line)
                self._add_line()
            
            # åˆ†éš”çº¿
            self._add_line("---")
            self._add_line()
        
        # æŠ¥å‘Šæ€»ç»“
        self._add_header("ğŸ“Š åˆ†ææ€»ç»“", 2)
        self._add_list_item(f"**æ€»èŒä½æ•°**: {len(analysis_results)}")
        self._add_list_item(f"**æ¨èæŠ•é€’**: {suitable_count} ä¸ª")
        self._add_list_item(f"**ä¸æ¨èæŠ•é€’**: {rejected_count} ä¸ª")
        self._add_list_item(f"**æ¨èç‡**: {suitable_count/len(analysis_results)*100:.1f}%")
        
        return "\n".join(self.report_content)


def create_markdown_report(analysis_results: List[Dict[str, Any]], 
                          experiences_data: List[Dict[str, Any]], 
                          output_path: str) -> None:
    """
    åˆ›å»ºMarkdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š
    
    Args:
        analysis_results: æ‰€æœ‰èŒä½çš„åˆ†æç»“æœ
        experiences_data: ç»å†æ•°æ®
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    generator = MarkdownReportGenerator()
    report_content = generator.generate_report(analysis_results, experiences_data)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"âœ… MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")